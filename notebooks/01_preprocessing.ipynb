{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Preprocessing Notebook\n",
        "\n",
        "This notebook handles data preprocessing for the Cirq-RAG-Code-Assistant project.\n",
        "\n",
        "## Purpose\n",
        "- Fetch quantum code from GitHub repositories\n",
        "- Load and clean knowledge base data\n",
        "- Process Cirq code snippets\n",
        "- Generate descriptions for code samples\n",
        "- Prepare data for embedding generation\n",
        "- Organize knowledge base structure\n",
        "\n",
        "## Usage\n",
        "Import preprocessing functions from `src.data` and use them to process your data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Imports\n",
        "\n",
        "Import the necessary modules for data fetching, preprocessing, and loading.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìÅ Project root: d:\\University\\Uni\\Semester 7\\Generative AI\\Project\\Cirq-RAG-Code-Assistant\n",
            "üìÅ Current directory: d:\\University\\Uni\\Semester 7\\Generative AI\\Project\\Cirq-RAG-Code-Assistant\\notebooks\n",
            "‚úÖ Imports successful!\n"
          ]
        }
      ],
      "source": [
        "# Add project root to Python path\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "# Get the project root (parent of notebooks directory)\n",
        "# In Jupyter notebooks, we need to navigate from the current working directory\n",
        "current_dir = Path(os.getcwd())\n",
        "# If we're in the notebooks directory, go up one level; otherwise assume we're at project root\n",
        "if current_dir.name == \"notebooks\":\n",
        "    project_root = current_dir.parent\n",
        "else:\n",
        "    # Try to find the project root by looking for src directory\n",
        "    project_root = current_dir\n",
        "    while project_root != project_root.parent:\n",
        "        if (project_root / \"src\").exists():\n",
        "            break\n",
        "        project_root = project_root.parent\n",
        "\n",
        "if str(project_root) not in sys.path:\n",
        "    sys.path.insert(0, str(project_root))\n",
        "\n",
        "print(f\"üìÅ Project root: {project_root}\")\n",
        "print(f\"üìÅ Current directory: {current_dir}\")\n",
        "\n",
        "# Import data processing modules\n",
        "from src.data.fetcher import DatasetFetcher\n",
        "from src.data.preprocessor import DataPreprocessor\n",
        "from src.data.description_generator import DescriptionGenerator\n",
        "from src.data.dataset_loader import DatasetLoader\n",
        "\n",
        "# Set up paths (relative to project root)\n",
        "DATA_DIR = project_root / \"data\" / \"datasets\"\n",
        "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"‚úÖ Imports successful!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Fetch Data from GitHub\n",
        "\n",
        "Fetch Cirq code samples from the Cirq GitHub repository.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Repository Cirq already exists. Skipping clone.\n",
            "Scanning 1175 Python files in Cirq...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Extracting Cirq code: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1175/1175 [00:00<00:00, 7258.06it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Collected 427 samples from https://github.com/quantumlib/Cirq\n",
            "\n",
            "============================================================\n",
            "‚úÖ Extraction complete!\n",
            "============================================================\n",
            "Total samples extracted: 427\n",
            "  - Cirq: 427 samples\n",
            "\n",
            "üíæ Saved to: d:\\University\\Uni\\Semester 7\\Generative AI\\Project\\Cirq-RAG-Code-Assistant\\data\\datasets\\quantum_code_samples_filtered.jsonl\n",
            "============================================================\n",
            "\n",
            "‚úÖ Data fetched and saved to: d:\\University\\Uni\\Semester 7\\Generative AI\\Project\\Cirq-RAG-Code-Assistant\\data\\datasets\\quantum_code_samples_filtered.jsonl\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Initialize fetcher\n",
        "fetcher = DatasetFetcher(\n",
        "    repos_dir=\"repos\",  # Directory to clone repositories\n",
        "    output_dir=DATA_DIR,  # Output directory for extracted data\n",
        ")\n",
        "\n",
        "# Fetch code from all repositories\n",
        "# Note: This will clone repositories if they don't exist\n",
        "# Set force_clone=True to re-clone existing repositories\n",
        "output_file = fetcher.fetch_all(\n",
        "    output_filename=\"quantum_code_samples_filtered.jsonl\",\n",
        "    force_clone=False,  # Set to True to re-clone\n",
        "    min_code_length=50,\n",
        "    max_code_length=50000,\n",
        ")\n",
        "\n",
        "print(f\"‚úÖ Data fetched and saved to: {output_file}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Load and Inspect Dataset\n",
        "\n",
        "Load the dataset and view statistics.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "Dataset Statistics: quantum_code_samples_filtered.jsonl\n",
            "============================================================\n",
            "Total entries: 427\n",
            "\n",
            "Frameworks:\n",
            "  - Cirq: 427\n",
            "\n",
            "Code length:\n",
            "  - Average: 9706 characters\n",
            "  - Min: 854 characters\n",
            "  - Max: 49381 characters\n",
            "\n",
            "Descriptions:\n",
            "  - With descriptions: 0\n",
            "  - Coverage: 0.0%\n",
            "============================================================\n",
            "\n",
            "\n",
            "üìã Sample entries:\n",
            "\n",
            "--- Sample 1 ---\n",
            "Framework: Cirq\n",
            "File: cirq-core\\cirq\\transformers\\gauge_compiling\\idle_moments_gauge.py\n",
            "Code length: 8517 characters\n",
            "Code preview: # Copyright 2025 The Cirq Developers\n",
            "#\n",
            "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
            "# you may not use this file except in compliance with the License.\n",
            "# You may obtain a copy of t...\n",
            "\n",
            "--- Sample 2 ---\n",
            "Framework: Cirq\n",
            "File: cirq-google\\cirq_google\\engine\\util.py\n",
            "Code length: 1357 characters\n",
            "Code preview: # Copyright 2022 The Cirq Developers\n",
            "#\n",
            "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
            "# you may not use this file except in compliance with the License.\n",
            "# You may obtain a copy of t...\n",
            "\n",
            "--- Sample 3 ---\n",
            "Framework: Cirq\n",
            "File: cirq-pasqal\\cirq_pasqal\\pasqal_noise_model.py\n",
            "Code length: 3295 characters\n",
            "Code preview: # Copyright 2020 The Cirq Developers\n",
            "#\n",
            "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
            "# you may not use this file except in compliance with the License.\n",
            "# You may obtain a copy of t...\n"
          ]
        }
      ],
      "source": [
        "# Load dataset\n",
        "dataset_path = DATA_DIR / \"quantum_code_samples_filtered.jsonl\"\n",
        "loader = DatasetLoader(dataset_path)\n",
        "\n",
        "# Print statistics\n",
        "loader.print_stats()\n",
        "\n",
        "# Get some sample entries\n",
        "samples = loader.sample(3, seed=42)\n",
        "print(\"\\nüìã Sample entries:\")\n",
        "for i, entry in enumerate(samples, 1):\n",
        "    print(f\"\\n--- Sample {i} ---\")\n",
        "    print(f\"Framework: {entry.get('framework')}\")\n",
        "    print(f\"File: {entry.get('file')}\")\n",
        "    print(f\"Code length: {len(entry.get('code', ''))} characters\")\n",
        "    print(f\"Code preview: {entry.get('code', '')[:200]}...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Preprocess Dataset\n",
        "\n",
        "Clean and validate the dataset, remove duplicates, and extract metadata.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading dataset from d:\\University\\Uni\\Semester 7\\Generative AI\\Project\\Cirq-RAG-Code-Assistant\\data\\datasets\\quantum_code_samples_filtered.jsonl...\n",
            "Preprocessing 427 entries...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Preprocessing:   0%|          | 0/427 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Preprocessing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 427/427 [00:00<00:00, 1026.12it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing preprocessed data to d:\\University\\Uni\\Semester 7\\Generative AI\\Project\\Cirq-RAG-Code-Assistant\\data\\datasets\\quantum_code_samples_preprocessed.jsonl...\n",
            "\n",
            "============================================================\n",
            "‚úÖ Preprocessing complete!\n",
            "============================================================\n",
            "Total entries: 427\n",
            "Processed: 0\n",
            "Filtered out: 427\n",
            "  - Duplicates: 0\n",
            "  - Quality issues: 427\n",
            "Retention rate: 0.0%\n",
            "\n",
            "üíæ Saved to: d:\\University\\Uni\\Semester 7\\Generative AI\\Project\\Cirq-RAG-Code-Assistant\\data\\datasets\\quantum_code_samples_preprocessed.jsonl\n",
            "\n",
            "‚ö†Ô∏è  Warning: All entries were filtered out!\n",
            "   Check your filtering criteria:\n",
            "   - min_code_length: 50\n",
            "   - max_code_length: 50000\n",
            "   - min_lines: 5\n",
            "   - max_lines: 1000\n",
            "   - validate_syntax: True\n",
            "\n",
            "   Sample quality issues found:\n",
            "   1. File: cirq-google\\cirq_google\\cloud\\quantum_v1alpha1\\services\\quantum_engine_service\\transports\\grpc.py\n",
            "      Code length: 49381, Lines: 1102\n",
            "      Issues: Too many lines: 1102 > 1000\n",
            "   2. File: cirq-google\\cirq_google\\cloud\\quantum_v1alpha1\\services\\quantum_engine_service\\transports\\rest_base.py\n",
            "      Code length: 39372, Lines: 1070\n",
            "      Issues: Too many lines: 1070 > 1000\n",
            "   3. File: cirq-core\\cirq\\experiments\\qubit_characterizations.py\n",
            "      Code length: 42016, Lines: 1099\n",
            "      Issues: Too many lines: 1099 > 1000\n",
            "============================================================\n",
            "\n",
            "‚úÖ Preprocessing complete! Processed 0 entries.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Initialize preprocessor\n",
        "preprocessor = DataPreprocessor(\n",
        "    min_code_length=50,\n",
        "    max_code_length=50000,\n",
        "    min_lines=5,\n",
        "    max_lines=1000,\n",
        "    remove_duplicates=True,\n",
        "    validate_syntax=True,\n",
        ")\n",
        "\n",
        "# Preprocess dataset\n",
        "input_file = DATA_DIR / \"quantum_code_samples_filtered.jsonl\"\n",
        "output_file = DATA_DIR / \"quantum_code_samples_preprocessed.jsonl\"\n",
        "\n",
        "stats = preprocessor.preprocess_dataset(\n",
        "    input_path=input_file,\n",
        "    output_path=output_file,\n",
        "    add_metadata=True,\n",
        ")\n",
        "\n",
        "print(f\"‚úÖ Preprocessing complete! Processed {stats['processed']} entries.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Generate Descriptions\n",
        "\n",
        "Add natural language descriptions to code samples.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading dataset from d:\\University\\Uni\\Semester 7\\Generative AI\\Project\\Cirq-RAG-Code-Assistant\\data\\datasets\\quantum_code_samples_preprocessed.jsonl...\n",
            "Generating descriptions for 0 entries...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating descriptions: 0it [00:00, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing output to d:\\University\\Uni\\Semester 7\\Generative AI\\Project\\Cirq-RAG-Code-Assistant\\data\\datasets\\quantum_dataset_with_descriptions.jsonl...\n",
            "\n",
            "============================================================\n",
            "‚úÖ Description generation complete!\n",
            "============================================================\n",
            "Total entries: 0\n",
            "Processed: 0\n",
            "Skipped: 0\n",
            "Errors: 0\n",
            "\n",
            "üíæ Saved to: d:\\University\\Uni\\Semester 7\\Generative AI\\Project\\Cirq-RAG-Code-Assistant\\data\\datasets\\quantum_dataset_with_descriptions.jsonl\n",
            "============================================================\n",
            "\n",
            "‚úÖ Descriptions generated! Processed 0 entries.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Initialize description generator\n",
        "# Set use_ml=True to use ML-based summarization (requires transformers)\n",
        "generator = DescriptionGenerator(\n",
        "    use_ml=False,  # Set to True for ML-enhanced descriptions\n",
        "    ml_model=\"facebook/bart-large-cnn\",\n",
        "    device=\"auto\",  # \"auto\", \"cpu\", or \"cuda\"\n",
        ")\n",
        "\n",
        "# Generate descriptions\n",
        "input_file = DATA_DIR / \"quantum_code_samples_preprocessed.jsonl\"\n",
        "output_file = DATA_DIR / \"quantum_dataset_with_descriptions.jsonl\"\n",
        "\n",
        "desc_stats = generator.add_descriptions_to_dataset(\n",
        "    input_path=input_file,\n",
        "    output_path=output_file,\n",
        "    use_ml=False,  # Override instance setting if needed\n",
        "    batch_size=100,\n",
        ")\n",
        "\n",
        "print(f\"‚úÖ Descriptions generated! Processed {desc_stats['processed']} entries.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Verify Final Dataset\n",
        "\n",
        "Load and verify the final preprocessed dataset with descriptions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "Dataset Statistics: quantum_dataset_with_descriptions.jsonl\n",
            "============================================================\n",
            "Total entries: 0\n",
            "\n",
            "Frameworks:\n",
            "\n",
            "Code length:\n",
            "  - Average: 0 characters\n",
            "  - Min: 0 characters\n",
            "  - Max: 0 characters\n",
            "\n",
            "Descriptions:\n",
            "  - With descriptions: 0\n",
            "  - Coverage: 0.0%\n",
            "============================================================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Load final dataset\n",
        "final_dataset = DatasetLoader(DATA_DIR / \"quantum_dataset_with_descriptions.jsonl\")\n",
        "\n",
        "# Print statistics\n",
        "final_dataset.print_stats()\n",
        "\n",
        "# View a sample entry with description\n",
        "samples = final_dataset.sample(1, seed=42)\n",
        "if samples:\n",
        "    entry = samples[0]\n",
        "    print(\"\\nüìã Sample entry with description:\")\n",
        "    print(f\"Framework: {entry.get('framework')}\")\n",
        "    print(f\"File: {entry.get('file')}\")\n",
        "    print(f\"\\nDescription:\")\n",
        "    print(entry.get('description', 'No description'))\n",
        "    print(f\"\\nMetadata:\")\n",
        "    if 'metadata' in entry:\n",
        "        for key, value in entry['metadata'].items():\n",
        "            print(f\"  - {key}: {value}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. View Cirq Samples\n",
        "\n",
        "View and analyze Cirq samples from the dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 0 Cirq samples\n"
          ]
        }
      ],
      "source": [
        "# Get all Cirq samples (all entries should be Cirq)\n",
        "cirq_samples = final_dataset.get_by_framework(\"Cirq\")\n",
        "print(f\"Found {len(cirq_samples)} Cirq samples\")\n",
        "\n",
        "# View a Cirq sample\n",
        "if cirq_samples:\n",
        "    sample = cirq_samples[0]\n",
        "    print(f\"\\nüìã Cirq Sample:\")\n",
        "    print(f\"File: {sample.get('file')}\")\n",
        "    print(f\"Description: {sample.get('description', 'No description')[:200]}...\")\n",
        "    print(f\"\\nCode preview:\")\n",
        "    print(sample.get('code', '')[:300] + \"...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Complete Pipeline\n",
        "\n",
        "Run the complete preprocessing pipeline in one go.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Complete preprocessing pipeline\n",
        "def run_preprocessing_pipeline(\n",
        "    fetch_data: bool = False,\n",
        "    generate_descriptions: bool = True,\n",
        "    use_ml: bool = False,\n",
        "):\n",
        "    \"\"\"\n",
        "    Run the complete data preprocessing pipeline.\n",
        "    \n",
        "    Args:\n",
        "        fetch_data: Whether to fetch data from GitHub\n",
        "        generate_descriptions: Whether to generate descriptions\n",
        "        use_ml: Whether to use ML for description generation\n",
        "    \"\"\"\n",
        "    # Step 1: Fetch data (optional, if not already done)\n",
        "    if fetch_data:\n",
        "        print(\"Step 1: Fetching data from GitHub...\")\n",
        "        fetcher = DatasetFetcher(output_dir=DATA_DIR)\n",
        "        fetcher.fetch_all()\n",
        "    \n",
        "    # Step 2: Preprocess data\n",
        "    print(\"\\nStep 2: Preprocessing data...\")\n",
        "    preprocessor = DataPreprocessor()\n",
        "    preprocessor.preprocess_dataset(\n",
        "        input_path=DATA_DIR / \"quantum_code_samples_filtered.jsonl\",\n",
        "        output_path=DATA_DIR / \"quantum_code_samples_preprocessed.jsonl\",\n",
        "    )\n",
        "    \n",
        "    # Step 3: Generate descriptions\n",
        "    if generate_descriptions:\n",
        "        print(\"\\nStep 3: Generating descriptions...\")\n",
        "        generator = DescriptionGenerator(use_ml=use_ml)\n",
        "        generator.add_descriptions_to_dataset(\n",
        "            input_path=DATA_DIR / \"quantum_code_samples_preprocessed.jsonl\",\n",
        "            output_path=DATA_DIR / \"quantum_dataset_with_descriptions.jsonl\",\n",
        "        )\n",
        "    \n",
        "    print(\"\\n‚úÖ Pipeline complete!\")\n",
        "\n",
        "# Uncomment to run the complete pipeline:\n",
        "# run_preprocessing_pipeline(fetch_data=False, generate_descriptions=True, use_ml=False)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv (3.13.2)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
