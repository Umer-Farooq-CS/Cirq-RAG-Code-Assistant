{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Embeddings Notebook\n",
        "\n",
        "This notebook handles embedding generation for the RAG system.\n",
        "\n",
        "## Purpose\n",
        "- Generate embeddings for knowledge base content\n",
        "- Create query embeddings\n",
        "- Test embedding models\n",
        "- Visualize embedding spaces\n",
        "\n",
        "## Usage\n",
        "Import embedding functions from src.rag.embeddings and generate embeddings for your data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup and Imports\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# Add project root to path\n",
        "project_root = Path(\"..\").resolve()\n",
        "sys.path.insert(0, str(project_root))\n",
        "\n",
        "# Import config from root config folder\n",
        "from config import get_config, get_config_loader\n",
        "\n",
        "# Import other modules\n",
        "from src.rag.embeddings import EmbeddingModel, create_embedding_model\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "print(\"✅ Imports successful!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize Configuration from config folder\n",
        "config = get_config()\n",
        "config_loader = get_config_loader()\n",
        "\n",
        "print(f\"Config loaded from: {config_loader.config_path}\")\n",
        "print(f\"Embedding Model: {config.get('models.embedding.model_name')}\")\n",
        "print(f\"Device: {config.get('models.embedding.device')}\")\n",
        "print(f\"Batch Size: {config.get('models.embedding.batch_size')}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Initialize Embedding Model\n",
        "\n",
        "Create an embedding model instance using the configured settings.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create embedding model\n",
        "embedding_model = EmbeddingModel(\n",
        "    model_name=config.get(\"models.embedding.model_name\"),\n",
        "    device=config.get(\"models.embedding.device\"),\n",
        ")\n",
        "\n",
        "print(f\"✅ Embedding model loaded: {embedding_model.model_name}\")\n",
        "print(f\"Embedding dimension: {embedding_model.get_embedding_dimension()}\")\n",
        "print(f\"Device: {embedding_model.device}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Generate Embeddings for Sample Texts\n",
        "\n",
        "Test embedding generation with sample Cirq-related texts.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sample texts for testing\n",
        "sample_texts = [\n",
        "    \"Create a 2-qubit Bell state circuit using Cirq\",\n",
        "    \"Implement a Grover search algorithm for 3 qubits\",\n",
        "    \"Build a VQE circuit for quantum chemistry\",\n",
        "    \"Generate a QAOA circuit for optimization\",\n",
        "    \"Create a quantum teleportation circuit\",\n",
        "]\n",
        "\n",
        "# Generate embeddings\n",
        "embeddings = embedding_model.encode(\n",
        "    sample_texts,\n",
        "    batch_size=config.get(\"models.embedding.batch_size\", 32),\n",
        "    show_progress_bar=True,\n",
        ")\n",
        "\n",
        "print(f\"✅ Generated embeddings for {len(sample_texts)} texts\")\n",
        "print(f\"Embedding shape: {embeddings.shape}\")\n",
        "print(f\"Embedding stats:\")\n",
        "print(f\"  Mean: {embeddings.mean():.4f}\")\n",
        "print(f\"  Std: {embeddings.std():.4f}\")\n",
        "print(f\"  Min: {embeddings.min():.4f}\")\n",
        "print(f\"  Max: {embeddings.max():.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Test Query Embeddings\n",
        "\n",
        "Generate embeddings for queries and compare with document embeddings.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate query embedding\n",
        "query = \"How to create a Bell state?\"\n",
        "query_embedding = embedding_model.encode_queries([query])\n",
        "\n",
        "print(f\"✅ Query embedding generated\")\n",
        "print(f\"Query: {query}\")\n",
        "print(f\"Query embedding shape: {query_embedding.shape}\")\n",
        "\n",
        "# Calculate similarity with sample texts\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "similarities = cosine_similarity(query_embedding, embeddings)[0]\n",
        "\n",
        "print(\"\\nSimilarity scores:\")\n",
        "for text, sim in zip(sample_texts, similarities):\n",
        "    print(f\"  {text[:50]}... : {sim:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Visualize Embeddings (PCA)\n",
        "\n",
        "Visualize embeddings in 2D using PCA for dimensionality reduction.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Reduce to 2D using PCA\n",
        "pca = PCA(n_components=2)\n",
        "embeddings_2d = pca.fit_transform(embeddings)\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], s=100, alpha=0.6)\n",
        "\n",
        "for i, text in enumerate(sample_texts):\n",
        "    plt.annotate(\n",
        "        text[:30] + \"...\",\n",
        "        (embeddings_2d[i, 0], embeddings_2d[i, 1]),\n",
        "        fontsize=8,\n",
        "    )\n",
        "\n",
        "plt.title(\"Embedding Visualization (PCA)\")\n",
        "plt.xlabel(\"PC1\")\n",
        "plt.ylabel(\"PC2\")\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"✅ Visualization complete\")\n",
        "print(f\"PCA explained variance: {pca.explained_variance_ratio_.sum():.2%}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Batch Processing\n",
        "\n",
        "Test batch processing for large-scale embedding generation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate more sample texts\n",
        "large_batch = [\n",
        "    f\"Cirq code example {i}: Create a quantum circuit with {i} qubits\"\n",
        "    for i in range(1, 21)\n",
        "]\n",
        "\n",
        "# Process in batches\n",
        "large_embeddings = embedding_model.encode(\n",
        "    large_batch,\n",
        "    batch_size=config.get(\"models.embedding.batch_size\", 32),\n",
        "    show_progress_bar=True,\n",
        ")\n",
        "\n",
        "print(f\"✅ Processed {len(large_batch)} texts in batches\")\n",
        "print(f\"Final embeddings shape: {large_embeddings.shape}\")\n",
        "\n",
        "# Check statistics\n",
        "stats = embedding_model.get_stats()\n",
        "print(f\"\\nEmbedding Statistics:\")\n",
        "print(f\"  Total embeddings: {stats['total_embeddings']}\")\n",
        "print(f\"  Total batches: {stats['total_batches']}\")\n",
        "print(f\"  Total texts: {stats['total_texts']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Model Information\n",
        "\n",
        "Display model information and capabilities.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Embedding Model Information:\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Model Name: {embedding_model.model_name}\")\n",
        "print(f\"Embedding Dimension: {embedding_model.get_embedding_dimension()}\")\n",
        "print(f\"Device: {embedding_model.device}\")\n",
        "print(f\"Model Type: {type(embedding_model.model).__name__}\")\n",
        "print(\"=\" * 60)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
